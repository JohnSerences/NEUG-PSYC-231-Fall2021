{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 11292021: Pandas, series, data frames \n",
    "* data structures and data analysis tools\n",
    "\n",
    "[The official project homepage](https://pandas.pydata.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data structures - start with Series then build up to DataFrames\n",
    "\n",
    "[Pandas quick start guide for Series](https://pandas.pydata.org/pandas-docs/stable/dsintro.html#series)\n",
    "\n",
    "* A **Series** is a 1D array that can hold any type of data (numeric types, non-numeric, Python objects and so forth).\n",
    "    * Unlike a 1D numpy array, each entry is **labeled** with an index that is used to keep track of what each entry is, and can be used to lookup the value corresponding to each index during analysis.\n",
    "    * These labels are fixed - they will always index the same value unless you explicitly break that link.\n",
    "    * The list of labels that forms the index can either be declared upon series creation or, by default, it will range from 0 to len(data)-1.\n",
    "        * If you're going to use Pandas to organize your data, specifying usable and informative labels is a good idea because that's one of the main advantages of organizing your data in this manner - if you just want to fly blind then NumPy is usually fine on its own\n",
    "        \n",
    "<div class=\"alert alert-warning\">\n",
    "Pandas will allow you to specify non-unique labels. This can be ok for operations that don't rely on indexing by label. However, operations that do rely on unique labels for indexing may throw an unexpected error so in general its good practice to use unique labels!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard numpy module\n",
    "import numpy as np\n",
    "\n",
    "# import a generic pandas object and also a few specific functions that we'll use\n",
    "import pandas as pd \n",
    "\n",
    "# new - get and store current file path for file i/o later on in tutorial\n",
    "import os\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a series from an numpy ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index labels:  ['Sub0', 'Sub1', 'Sub2', 'Sub3', 'Sub4', 'Sub5', 'Sub6', 'Sub7', 'Sub8', 'Sub9', 'Sub10', 'Sub11'] \n",
      "\n",
      "Sub0     0.548814\n",
      "Sub1     0.715189\n",
      "Sub2     0.602763\n",
      "Sub3     0.544883\n",
      "Sub4     0.423655\n",
      "Sub5     0.645894\n",
      "Sub6     0.437587\n",
      "Sub7     0.891773\n",
      "Sub8     0.963663\n",
      "Sub9     0.383442\n",
      "Sub10    0.791725\n",
      "Sub11    0.528895\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# make some data and then use pd.Series\n",
    "\n",
    "# random seed so we get the same thing each time \n",
    "np.random.seed(0)\n",
    "\n",
    "# For this simulation, lets have 12 subjects, and some data\n",
    "N = 12\n",
    "data = np.random.random(N)\n",
    "\n",
    "# make a list of subject names for use as index labels\n",
    "label_prefix = 'Sub'\n",
    "index=[]\n",
    "for n in np.arange(N):\n",
    "    index.append(label_prefix+str(n))\n",
    "\n",
    "# print our list of index labels\n",
    "print('Index labels: ', index, '\\n')\n",
    "\n",
    "# then make our pandas Series by passing in our data array and our index labels\n",
    "s = pd.Series(data, index=index)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note that each subject is now a field in the series and can be used to retrieve the corresponding value...there are a few ways to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5288949197529045\n",
      "0.5288949197529045\n"
     ]
    }
   ],
   "source": [
    "# access by field\n",
    "print(s.Sub11)\n",
    "\n",
    "# access by index label\n",
    "print(s['Sub11'])\n",
    "\n",
    "# will cover more advanced slicing below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can also use labels to check for membership or to index over labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "\n",
      "\n",
      "Sub0\n",
      "Sub1\n",
      "Sub2\n",
      "Sub3\n",
      "Sub4\n",
      "Sub5\n",
      "Sub6\n",
      "Sub7\n",
      "Sub8\n",
      "Sub9\n",
      "Sub10\n",
      "Sub11\n",
      "\n",
      "\n",
      "0.5488135039273248\n",
      "0.7151893663724195\n",
      "0.6027633760716439\n",
      "0.5448831829968969\n",
      "0.4236547993389047\n",
      "0.6458941130666561\n",
      "0.4375872112626925\n",
      "0.8917730007820798\n",
      "0.9636627605010293\n",
      "0.3834415188257777\n",
      "0.7917250380826646\n",
      "0.5288949197529045\n"
     ]
    }
   ],
   "source": [
    "# check for membership\n",
    "print('Sub11' in s)\n",
    "print('\\n')\n",
    "\n",
    "# iterate over index labels, with l==index name\n",
    "for l in s.index:\n",
    "    print(l)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# iterate over values...\n",
    "for l in s.values:\n",
    "    print(l)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5488135039273248\n",
      "0.7151893663724195\n",
      "0.6027633760716439\n",
      "0.5448831829968969\n",
      "0.4236547993389047\n",
      "0.6458941130666561\n",
      "0.4375872112626925\n",
      "0.8917730007820798\n",
      "0.9636627605010293\n",
      "0.3834415188257777\n",
      "0.7917250380826646\n",
      "0.5288949197529045\n"
     ]
    }
   ],
   "source": [
    "# can also get to the values more directly like this:\n",
    "for d in s:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before moving on, there are a few other optional (but important) parameters of the pd.Series call\n",
    "* dtype - default is to infer the data type (int32, float64, str, etc) based on the values in data\n",
    "    * However, can also explicitly declare the data\n",
    "    * This can be good if you want to, for example, re-cast the data to save space or to make types compatible\n",
    "    * But this may also have important negative consequences if not done thoughtfully! \n",
    "* copy - if not specified then the default behavior is set to False and the new series will have a 'view' of the data.\n",
    "    * This can save space, but can sometimes lead to confusion as any change to the values in s will also change the values in the original 'data' array\n",
    "    * Setting copy=False will make a new copy of the data in 's' that is independent of the input 'data' array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example for using dtype: declaring dtype can be handy if you want to, for example, do str manipulations with the data array later or if you want to merge with another series of type str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5488135  0.71518937 0.60276338 0.54488318]\n",
      "\n",
      " Sub0    0.5488135039273248\n",
      "Sub1    0.7151893663724195\n",
      "Sub2    0.6027633760716439\n",
      "Sub3    0.5448831829968969\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# make a series with the data array from above, but this time make it a str\n",
    "# instead of the inferred float64 type\n",
    "s = pd.Series(data, index=index, dtype='str')\n",
    "\n",
    "# first 4 values in our original data array\n",
    "print(data[:4])\n",
    "\n",
    "# first 4 values in our series of type str...preserves info and we're now\n",
    "# all set to do a bunch of str operation without having to deal with \n",
    "# recasting each time we interact with the values in s\n",
    "print('\\n', s[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Note that the dtype of series 's' is now an 'object'. This is the Pandas version of a Python 'str'\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now explicitly ask for a 'copy' of the data instead of the default view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:  [0 1 2 3] \n",
      "\n",
      "Original values in series\n",
      "d1    0\n",
      "d2    1\n",
      "d3    2\n",
      "d4    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Same as before - create a series based on a short data array (0:4 in this case for simplicity)\n",
    "# let Pandas figure out the dtype, and use the default copy behavior (i.e. copy=False)\n",
    "\n",
    "N = 4                # number of data points\n",
    "\n",
    "# make data\n",
    "data = np.arange(N)\n",
    "\n",
    "# make index labels\n",
    "index = ['d1','d2','d3','d4']\n",
    "\n",
    "# print out the original data array for reference\n",
    "print('Original data: ', data, '\\n')\n",
    "\n",
    "# make a series with the default behavior of copy=False\n",
    "s = pd.Series(data, index=index, copy=False)\n",
    "\n",
    "# print out the new series\n",
    "print('Original values in series')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New values in series\n",
      "d1    100\n",
      "d2      1\n",
      "d3      2\n",
      "d4      3\n",
      "dtype: int64\n",
      "\n",
      "New data: [0 1 2 3] \n",
      "data[0] changed too!\n"
     ]
    }
   ],
   "source": [
    "# now change the value of the first entry in the series\n",
    "s['d1'] = 100\n",
    "\n",
    "# new values in series 's'\n",
    "print('\\nNew values in series')\n",
    "print(s)\n",
    "\n",
    "# and then print the corresponding entry in the data array\n",
    "print('\\nNew data:', data, '\\ndata[0] changed too!')\n",
    "\n",
    "# Note that data[0] changed because the values in s are a view of data...\n",
    "# both are referencing the same chunk of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "Note that this works in the other direction too, which can be more insidious...if you create a Series based on the values in 'data', and then do more work with 'data', then every time you change a value in the original data array, you will also change the corresponding value in s!!!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After creating a pandas series, you can do many common operations and access the functionality of other modules \n",
    "* A pd Series behaves similar to a NumPy ndarray, and can be passed to many NumPy functions\n",
    "* Slicing also works like a ndarray - note that index is also sliced\n",
    "* Lots of built in methods as well that emulate NumPy functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can pass pd.Series to most NumPy functions... \n",
    "* Note that the index labels come along for the ride "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1    100\n",
      "d2      1\n",
      "d3      2\n",
      "d4      3\n",
      "dtype: int64\n",
      "\n",
      "Cumproduct\n",
      "\n",
      "d1    100\n",
      "d2    100\n",
      "d3    200\n",
      "d4    600\n",
      "dtype: int64\n",
      "\n",
      "Index by label\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# print our series - set of index labels along with data values\n",
    "print(s)\n",
    "\n",
    "# then apply the NumPy cumulative product operation (multiply N with N+1, then that result by N+2, etc)\n",
    "cp = np.cumprod(s)\n",
    "\n",
    "print('\\nCumproduct\\n')\n",
    "print(cp)\n",
    "\n",
    "# cool part: note that the output also contains the label info, which is handy to keep track of things,\n",
    "# e.g. you can index into cp using thes labels\n",
    "print('\\nIndex by label')\n",
    "print(cp['d1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series objects have many built in operations, much like NumPy \n",
    "[list of attributes and methods](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.Series.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type:  int64\n",
      "Mean:  1.5  Std: 1.2909944487358056 Max:  3\n",
      "Diff:  d1    NaN\n",
      "d2    1.0\n",
      "d3    1.0\n",
      "d4    1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# attributes\n",
    "print('Data Type: ', s.dtype)\n",
    "\n",
    "# basic methods\n",
    "print('Mean: ', s.mean(), ' Std:', s.std(), 'Max: ', s.max())\n",
    "\n",
    "# numerical derivative\n",
    "print('Diff: ', s.diff())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing also works like NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1    0\n",
      "d2    1\n",
      "d3    2\n",
      "d4    3\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "First 3 entries\n",
      "d1    0\n",
      "d2    1\n",
      "d3    2\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "S * 22\n",
      "d1     0\n",
      "d2    22\n",
      "d3    44\n",
      "d4    66\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print the series\n",
    "print(s)\n",
    "print('\\n')\n",
    "\n",
    "# first 3 values\n",
    "print('First 3 entries')\n",
    "print(s[:3])\n",
    "print('\\n')\n",
    "\n",
    "# Unary operations\n",
    "print('S * 22')\n",
    "print(s * 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that after slicing, labels stay attached to data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values >= 2\n",
      "d1    100\n",
      "d3      2\n",
      "d4      3\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example using conditional indexing: find all entries where data > .9\n",
    "print('Values >= 2')\n",
    "new_s = s[s>=2]\n",
    "print(new_s)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "The fact that labels stay attached to the corresponding values is often useful beacuse you don't have to compute and store a separate index for the new data set like you would in Matlab if you wanted to keep track of where the values > 2 were in the original array.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Although series can be treated much like NumPy arrays, there is one key difference (and often a big advantage)\n",
    "* When you do an operation on a NumPy array, the operation is performed in an element-by-element manner\n",
    "* However, when you do an operation on two pandas series, the operation will be applied to like-labeled values\n",
    "* This can save a lot of trouble in terms of lining up corresponding entries in two data arrays when the data sets are initialized in different orders!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Info alert - the next part is neat and really really useful in many real world applications where data sets are messy...Series operations are performed based on matching labels, not on matching positions in an array!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following on the NumPy example in the last cell...Now suppose that you ran a set of subjects in two experiments, but the data from each subject were entered in a different order in each study\n",
    "* Even though the data were entered in different orders, you want an easy way to perform operations on specific subjects across experiments \n",
    "* Using NumPy - or Matlab - you'd probably now try to sort your second data set so that the labels from the second study were in the same order as in the first study.\n",
    "* Then you would save an index indicating the sort order, and you'd use that index to rearange the data values from the second data set so that everything lined up with the first data set.\n",
    "* A series can make life much easier here because operations are done on a union of the labels involved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up two series - as if we have two data sets from the same set of 5 participants\n",
    "N=5\n",
    "data0 = np.arange(N)\n",
    "index0 = ['s0','s1','s2','s3','s4']\n",
    "s0 = pd.Series(data0, index=index0)\n",
    "\n",
    "# now do our second 'experiment' but this time the subjects were run in a different order\n",
    "data1 = np.arange(N)+7\n",
    "index1 = ['s3','s2','s4','s1','s0']\n",
    "s1 = pd.Series(data1, index=index1)\n",
    "\n",
    "# print out our data series\n",
    "print(s0)\n",
    "print('\\nData from the second experiment - same subjects, but different order\\n')\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a simple unary operation like addition across data sets\n",
    "sum_data = s0+s1\n",
    "print(sum_data)\n",
    "# Even though the numerical position of each subject differs across experiments, Pandas figured out how \n",
    "# to properly perform the operation by aligning based on index labels!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last notes on creation of series (not covered in class)\n",
    "* Thus far we've been initializing series with ndarrays\n",
    "* Can also make series from scalars (assign all indices same value) or from dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppose you want a series with all the same values...you can do this using np.repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14\n",
       "1    14\n",
       "2    14\n",
       "3    14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N=4\n",
    "data = np.repeat(14, N)\n",
    "index = np.arange(N) \n",
    "\n",
    "# make the series\n",
    "s = pd.Series(data, index=index)\n",
    "\n",
    "# all entries will have the same value\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OR you can achieve the same thing in a more straightforward manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14\n",
       "1    14\n",
       "2    14\n",
       "3    14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# series from scalars\n",
    "N=4\n",
    "\n",
    "# don't need repeat cause its a single scalar linked to each index\n",
    "data = 14\n",
    "index = np.arange(N) \n",
    "\n",
    "# make the series\n",
    "s = pd.Series(data, index=index)\n",
    "\n",
    "# all entries will have the same value\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can also initialize with a dict\n",
    "* dict keys become index labels\n",
    "* data become values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob     20.0\n",
      "Ella    17.0\n",
      "Sam     23.0\n",
      "Jack    25.3\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data = {'Bob' : 20, 'Ella' : 17, 'Sam' : 23, 'Jack' : 25.3}\n",
    "s = pd.Series(data)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Note that data type is upcast to highest precision entry when you create a Series with mixed numerical data types\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
